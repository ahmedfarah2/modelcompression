{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbpKDmxJ2XTZ",
        "outputId": "5afd63a5-ec6b-499a-81eb-86a7afca6689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "import time\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and split the IMDB dataset\n",
        "dataset = load_dataset('imdb')\n",
        "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select([i for i in range(1500)])\n",
        "small_test_dataset = dataset[\"test\"].shuffle(seed=42).select([i for i in range(500)])\n",
        "\n",
        "# Split the training dataset into training and validation sets\n",
        "train_val_split = small_train_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = train_val_split[\"train\"]\n",
        "validation_dataset = train_val_split[\"test\"]\n",
        "\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(validation_dataset)}\")\n",
        "print(f\"Test set size: {len(small_test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdZrRL6y3i8n",
        "outputId": "c0bcebce-93f8-4be4-9eab-d7f27e3af6b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1200\n",
            "Validation set size: 300\n",
            "Test set size: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer and tokenize datasets\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "validation_dataset = validation_dataset.map(tokenize_function, batched=True)\n",
        "small_test_dataset = small_test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "validation_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "small_test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
      ],
      "metadata": {
        "id": "AueZVlx33lbg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "print(f\"Model loaded with {sum(p.numel() for p in model.parameters())} parameters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T96WO1Em-_Tg",
        "outputId": "9f5835b0-a36f-4d4f-a064-4ca2b80bf036"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded with 109483778 parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define pruning functions\n",
        "from torch.nn.utils import prune\n",
        "\n",
        "def calculate_pruning_impact(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    total_intermediate_weights = 0\n",
        "    total_intermediate_zero_weights = 0\n",
        "\n",
        "    for transformer_layer in model.bert.encoder.layer:\n",
        "        weights = transformer_layer.intermediate.dense.weight.detach().cpu()\n",
        "        total_intermediate_weights += weights.numel()\n",
        "        total_intermediate_zero_weights += (weights == 0).sum().item()\n",
        "\n",
        "    remaining_params = total_params - total_intermediate_zero_weights\n",
        "    percent_deducted = (total_intermediate_zero_weights / total_params) * 100\n",
        "    print(f\"Total Parameters: {total_params}, Zero Parameters: {total_intermediate_zero_weights}, Remaining Parameters: {remaining_params}, Pruned Percentage: {percent_deducted:.2f}%\")\n",
        "    return total_params, total_intermediate_zero_weights, remaining_params, percent_deducted\n",
        "\n",
        "def prune_layer(layer, amount=0.2):\n",
        "    prune.l1_unstructured(layer, name=\"weight\", amount=amount)"
      ],
      "metadata": {
        "id": "3bT3b1PM3sHE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Calculating original model parameters...\")\n",
        "original_model_memory, _, _, _ = calculate_pruning_impact(model)\n",
        "\n",
        "for layer in model.bert.encoder.layer:\n",
        "    prune_layer(layer.intermediate.dense, amount=0.2)\n",
        "    prune_layer(layer.output.dense, amount=0.2)\n",
        "\n",
        "print(\"Calculating pruned model parameters...\")\n",
        "_, _, pruned_model_memory, _ = calculate_pruning_impact(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_81HQ5_q3shc",
        "outputId": "635d5765-0638-4e9d-bc72-dcdc0585a3ce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating original model parameters...\n",
            "Total Parameters: 109483778, Zero Parameters: 0, Remaining Parameters: 109483778, Pruned Percentage: 0.00%\n",
            "Calculating pruned model parameters...\n",
            "Total Parameters: 109483778, Zero Parameters: 5662308, Remaining Parameters: 103821470, Pruned Percentage: 5.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments for the pruned model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./pruned_bert_output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir=\"./pruned_logs\",\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Trainer for the pruned model with EarlyStoppingCallback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "N8KQPR1u3vU9",
        "outputId": "e415251b-70bf-42c8-d054-d44ab3b29437"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='450' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 450/1500 02:24 < 05:37, 3.11 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.561400</td>\n",
              "      <td>0.484335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.356800</td>\n",
              "      <td>0.627354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.201300</td>\n",
              "      <td>0.612039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=450, training_loss=0.3731534915500217, metrics={'train_runtime': 144.556, 'train_samples_per_second': 83.013, 'train_steps_per_second': 10.377, 'total_flos': 236799949824000.0, 'train_loss': 0.3731534915500217, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments for the original model\n",
        "original_training_args = TrainingArguments(\n",
        "    output_dir=\"./original_bert_output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir=\"./original_logs\",\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Load the original model\n",
        "original_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "#trainer for the original model with EarlyStoppingCallback\n",
        "original_trainer = Trainer(\n",
        "    model=original_model,\n",
        "    args=original_training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "original_trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "V9RGoHVS3yQi",
        "outputId": "58ceb3fb-da87-4e39-bfc0-43d6f1438622"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 750/1500 03:36 < 03:37, 3.46 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.715800</td>\n",
              "      <td>0.689144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.592300</td>\n",
              "      <td>0.454334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.375700</td>\n",
              "      <td>0.507343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.170100</td>\n",
              "      <td>0.683319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.072100</td>\n",
              "      <td>0.723657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=750, training_loss=0.38518287022908526, metrics={'train_runtime': 216.6718, 'train_samples_per_second': 55.383, 'train_steps_per_second': 6.923, 'total_flos': 394666583040000.0, 'train_loss': 0.38518287022908526, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function for metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
        "\n",
        "trainer.compute_metrics = compute_metrics\n",
        "original_trainer.compute_metrics = compute_metrics\n",
        "\n",
        "# Evaluate both models on the validation set\n",
        "pruned_validation_results = trainer.evaluate(eval_dataset=validation_dataset)\n",
        "original_validation_results = original_trainer.evaluate(eval_dataset=validation_dataset)\n",
        "\n",
        "print(f\"Pruned Model Validation Accuracy: {pruned_validation_results['eval_accuracy'] * 100:.2f}%\")\n",
        "print(f\"Original Model Validation Accuracy: {original_validation_results['eval_accuracy'] * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "p9rbuNcS32GO",
        "outputId": "dea4aabe-1113-4805-a5d5-f90d281a67a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [38/38 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [38/38 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned Model Validation Accuracy: 78.00%\n",
            "Original Model Validation Accuracy: 77.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_test_results = trainer.evaluate(eval_dataset=small_test_dataset)\n",
        "original_test_results = original_trainer.evaluate(eval_dataset=small_test_dataset)\n",
        "\n",
        "print(f\"Pruned Model Test Accuracy: {pruned_test_results['eval_accuracy'] * 100:.2f}%\")\n",
        "print(f\"Original Model Test Accuracy: {original_test_results['eval_accuracy'] * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "J4EmDXszA-VB",
        "outputId": "d2cb1ce2-0e71-4b6a-aba1-46aaa903f384"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [38/38 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [38/38 00:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned Model Test Accuracy: 75.00%\n",
            "Original Model Test Accuracy: 79.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_inference_time(model, dataset, batch_size=8, num_batches=10):\n",
        "    model.eval()\n",
        "    model.to('cuda')\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    times = []\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "            inputs = {k: v.to('cuda') for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            torch.cuda.synchronize()\n",
        "            start_time = time.time()\n",
        "            _ = model(**inputs)\n",
        "            torch.cuda.synchronize()\n",
        "            end_time = time.time()\n",
        "            times.append(end_time - start_time)\n",
        "\n",
        "    avg_time = sum(times) / len(times)\n",
        "    return avg_time\n",
        "\n",
        "pruned_inference_time = measure_inference_time(model, small_test_dataset)\n",
        "non_pruned_inference_time = measure_inference_time(original_model, small_test_dataset)\n",
        "\n",
        "print(f\"Pruned Model Inference Time: {pruned_inference_time:.4f} seconds\")\n",
        "print(f\"Original Model Inference Time: {non_pruned_inference_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SymPps5U339d",
        "outputId": "4d5bc4b9-2166-424e-e5af-3385b46f5d65"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned Model Inference Time: 0.0560 seconds\n",
            "Original Model Inference Time: 0.0557 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_file(\n",
        "    pruning_type,\n",
        "    dataset_used,\n",
        "    num_samples,\n",
        "    original_model_memory,\n",
        "    original_model_accuracy_score,\n",
        "    original_model_avg_time,\n",
        "    pruned_model_memory,\n",
        "    pruned_model_accuracy_score,\n",
        "    pruned_model_avg_time\n",
        "):\n",
        "    file_name = f\"{pruning_type}_pruning_summary.txt\"\n",
        "    content = (\n",
        "        f\"Pruning Method: {pruning_type.capitalize()} Pruning\\n\"\n",
        "        f\"Dataset Used: {dataset_used}\\n\"\n",
        "        f\"Number of Samples for Inference: {num_samples}\\n\\n\"\n",
        "        f\"Original Model Parameters: {original_model_memory:,}\\n\"\n",
        "        f\"Original Model Accuracy (%): {original_model_accuracy_score:.2f}\\n\"\n",
        "        f\"Original Model Inference Time (avg seconds): {original_model_avg_time:.4f}\\n\\n\"\n",
        "        f\"Pruned Model Parameters: {pruned_model_memory:,}\\n\"\n",
        "        f\"Pruned Model Accuracy (%): {pruned_model_accuracy_score:.2f}\\n\"\n",
        "        f\"Pruned Model Inference Time (avg seconds): {pruned_model_avg_time:.4f}\\n\"\n",
        "    )\n",
        "    file_path = os.path.join(os.getcwd(), file_name)\n",
        "    with open(file_path, \"w\") as file:\n",
        "        file.write(content)\n",
        "    print(f\"Summary saved to: {file_path}\")"
      ],
      "metadata": {
        "id": "pUwFihPiERqc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_file(\n",
        "    pruning_type=\"unstructured\",\n",
        "    dataset_used=\"IMDB\",\n",
        "    num_samples=len(small_test_dataset),\n",
        "    original_model_memory=original_model_memory,\n",
        "    original_model_accuracy_score=original_test_results['eval_accuracy'] * 100,\n",
        "    original_model_avg_time=non_pruned_inference_time,\n",
        "    pruned_model_memory=pruned_model_memory,\n",
        "    pruned_model_accuracy_score=pruned_test_results['eval_accuracy'] * 100,\n",
        "    pruned_model_avg_time=pruned_inference_time\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkCNe1PFEPls",
        "outputId": "d699a94e-3dc6-48f4-c500-bb7b70b95c38"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary saved to: /content/unstructured_pruning_summary.txt\n"
          ]
        }
      ]
    }
  ]
}